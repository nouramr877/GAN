{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndBzCtKHBdhr"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('content')"
      ],
      "metadata": {
        "id": "9DTvE2ArEEJu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "k3CSPw2hEEN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/content/MyDrive/kaggle.json ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "naTKKpiVEEQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "rSpYCc9QEETy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 giga dataset\n",
        "!kaggle datasets download -d vikramtiwari/pix2pix-dataset"
      ],
      "metadata": {
        "id": "GkH2s-slEEWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/pix2pix-dataset.zip"
      ],
      "metadata": {
        "id": "7Xd1kWKhEEZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, Conv2D, Flatten, BatchNormalization, LeakyReLU\n",
        "from keras.layers import Conv2DTranspose, Dropout, ReLU, Input, Concatenate, ZeroPadding2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import plot_model"
      ],
      "metadata": {
        "id": "NhGVeC9KEEb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 1\n",
        "IMAGE_SIZE = 256"
      ],
      "metadata": {
        "id": "QmfHHk5FEEen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load(image_file):                                      # like /content/train/*jpg\n",
        "    image = tf.io.read_file(image_file)                    #save this data but encoded\n",
        "    image = tf.image.decode_jpeg(image, channels=3)        #decode this saved img\n",
        "    w = tf.shape(image)[1]\n",
        "    w = w//2\n",
        "    real_image = image[:, :w, :]\n",
        "    input_image = image[:, w:, :]\n",
        "\n",
        "    input_image = tf.cast(input_image, tf.float32)         #turn it to float from int using cast\n",
        "    real_image = tf.cast(real_image, tf.float32)\n",
        "    return input_image, real_image\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QjIqtjYPEEhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#test for load data\n",
        "\n",
        "path = \"cityscapes/cityscapes/\"\n",
        "x,y = load(os.path.join(path, \"train/1.jpg\")) #join mean add train/1.jpg after path cityscapes/cityscapes/\n",
        "print(x.shape, y.shape)\n"
      ],
      "metadata": {
        "id": "gRz0xPzEIKWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize\n",
        "fig, axes = plt.subplots(1,2, figsize = (16,5))\n",
        "axes[0].imshow(x/255.0)                            #axes[0] mean first img\n",
        "axes[1].imshow(y/255.0)"
      ],
      "metadata": {
        "id": "GkceWDrdEEmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#normilize to -1 to 1 as we use tansh and lekyrelu which take range -1:1\n",
        "\n",
        "def normalize(input_image, real_image):\n",
        "    input_image = (input_image / 127.5) - 1\n",
        "    real_image = (real_image / 127.5) - 1\n",
        "    return input_image, real_image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#resize img to IMAGE_SIZE = 256\n",
        "def resize(input_image, real_image):\n",
        "    input_image = tf.image.resize(input_image, [IMAGE_SIZE, IMAGE_SIZE], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    real_image = tf.image.resize(real_image, [IMAGE_SIZE, IMAGE_SIZE], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    return input_image, real_image\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# replace some img with same img but fliping horrizontal\n",
        "def random_jitter(input_image, real_image):\n",
        "    #if tf.random.uniform(()) > 0.5:\n",
        "    input_image = tf.image.flip_left_right(input_image)\n",
        "    real_image = tf.image.flip_left_right(real_image)\n",
        "    return input_image, real_image\n"
      ],
      "metadata": {
        "id": "cU-mOhaYEEpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_jit, y_jit = random_jitter(x, y)\n",
        "fig, axes = plt.subplots(1,2, figsize = (16,5))\n",
        "axes[0].imshow(x_jit/255.0)\n",
        "axes[1].imshow(y_jit/255.0)"
      ],
      "metadata": {
        "id": "UcPYFvcMEEre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take images path \"cityscapes/cityscapes/train/*jpg\"   * mean take any img in train end by jpg\n",
        "#after take path load data and resize and flip some of them then normalize\n",
        "\n",
        "def load_train_images(image_path):\n",
        "    input_image, real_image = load(image_path)\n",
        "    input_image, real_image = resize(input_image, real_image)\n",
        "    input_image, real_image = random_jitter(input_image, real_image)\n",
        "    input_image, real_image = normalize(input_image, real_image)\n",
        "    return input_image,real_image\n",
        "\n",
        "\n",
        "\n",
        "def load_test_image(image_path):\n",
        "    input_image, real_image = load(image_path)\n",
        "    input_image, real_image = resize(input_image, real_image)\n",
        "    input_image, real_image = normalize(input_image, real_image)\n",
        "    return input_image, real_image"
      ],
      "metadata": {
        "id": "kfAH_BmwEEuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create input pipeline\n",
        "train_dataset = tf.data.Dataset.list_files(path + \"train/*.jpg\")  #load img in this folder\n",
        "train_dataset = train_dataset.map(load_train_images)       #using map apply load_train_images fun on prev line\n",
        "\n",
        "#take only 10 img from dataset and choose 1(BATCH_SIZE) image randomly then take another one randomly till 10 img\n",
        "#end then take another 10 img and repat process this is good for memory\n",
        "# tajecare that load_train_images should return two var but we save this 2 var in one called train_dataset\n",
        "train_dataset = train_dataset.shuffle(10).batch(BATCH_SIZE)\n",
        "train_dataset"
      ],
      "metadata": {
        "id": "nMXR7ZNREExc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = tf.data.Dataset.list_files(path + \"val/*.jpg\")\n",
        "test_dataset = test_dataset.map(load_test_image)\n",
        "test_dataset = test_dataset.batch(BATCH_SIZE)\n",
        "test_dataset"
      ],
      "metadata": {
        "id": "uITrIL8YEE1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# downsample block\n",
        "def downsample(filters, size, batchnorm = True):\n",
        "    init = tf.random_normal_initializer(0.,0.02)   #intilize weight of neoural network with mean=0 and std = 0.02\n",
        "    result = Sequential()\n",
        "    result.add(Conv2D(filters, size, strides = 2, padding = \"same\", kernel_initializer = init, use_bias = False))\n",
        "    if batchnorm == True:\n",
        "        result.add(BatchNormalization())\n",
        "\n",
        "    result.add(LeakyReLU())\n",
        "    return result\n",
        "down_model = downsample(3,4)\n",
        "down_result = down_model(tf.expand_dims(x, axis = 0)) # axis = 0 mean put number of img you do down sample => (1,256,256,3)\n",
        "print(down_result.shape)"
      ],
      "metadata": {
        "id": "vLPPGcwNEE4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upsample block\n",
        "def upsample(filters, size, dropout = False):\n",
        "    init = tf.random_normal_initializer(0, 0.02)\n",
        "    result = Sequential()\n",
        "    result.add(Conv2DTranspose(filters, size, strides = 2, padding = \"same\", kernel_initializer = init, use_bias = False))\n",
        "    result.add(BatchNormalization())\n",
        "    if dropout == True:\n",
        "        result.add(Dropout(0.5))\n",
        "    result.add(ReLU())\n",
        "    return result\n",
        "up_model = upsample(3,4)\n",
        "up_result = up_model(down_result)\n",
        "print(up_result.shape)"
      ],
      "metadata": {
        "id": "PQPVS1UWEE7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generator():\n",
        "    inputs = Input(shape = [IMAGE_SIZE, IMAGE_SIZE, 3])\n",
        "    down_stack = [\n",
        "        downsample(64, 4, batchnorm=False),\n",
        "        downsample(128, 4),\n",
        "        downsample(256, 4),\n",
        "        downsample(512, 4),\n",
        "        downsample(512, 4),\n",
        "        downsample(512, 4),\n",
        "        downsample(512, 4),\n",
        "        downsample(512, 4)\n",
        "    ]\n",
        "\n",
        "\n",
        "    up_stack = [\n",
        "        upsample(512, 4, dropout=True),\n",
        "        upsample(512, 4, dropout=True),\n",
        "        upsample(512, 4),\n",
        "        upsample(512, 4),\n",
        "        upsample(256, 4),\n",
        "        upsample(128, 4),\n",
        "        upsample(64, 4),\n",
        "    ]\n",
        "    init = tf.random_normal_initializer(0., 0.02)\n",
        "    last = Conv2DTranspose(3, 4, strides = 2, padding = \"same\", kernel_initializer = init, activation =\"tanh\")\n",
        "    x = inputs\n",
        "    skips = []\n",
        "    for down in down_stack:   #make skip connection\n",
        "        x = down(x)\n",
        "        skips.append(x)\n",
        "    skips = reversed(skips[:-1])   #skip list now have[d8,d7,d6,...,d1]\n",
        "\n",
        "    for up, skip in zip(up_stack, skips):\n",
        "        x = up(x)\n",
        "        x = Concatenate()([x, skip])  #concatenate list have [u1&d8 , u2&d7 , ... , u8&d1]\n",
        "\n",
        "    x = last(x)\n",
        "    return Model(inputs = inputs, outputs = x)"
      ],
      "metadata": {
        "id": "tpr8VZEQEE-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "gen = generator()\n",
        "gen.summary()"
      ],
      "metadata": {
        "id": "bKkeRHiO5AlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(gen, show_shapes=True, dpi = 64)\n"
      ],
      "metadata": {
        "id": "CKIOvYVG5Aos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.losses import BinaryCrossentropy\n",
        "loss_function = BinaryCrossentropy(from_logits=True)\n"
      ],
      "metadata": {
        "id": "zpSDuxik5Ar5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# take o/p of discremnator on fake img and o/p of generator and real img\n",
        "def generator_loss(disc_generated_output, gen_output, target):\n",
        "    #we fill matrix with one as we try to cheat discremnator to make it predict fake img(0) as real img(1)\n",
        "\n",
        "    gan_loss = loss_function(tf.ones_like(disc_generated_output), disc_generated_output)  # gan_loss is univeral loss\n",
        "    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))\n",
        "    total_gen_loss = gan_loss + (LAMBDA * l1_loss) # total_gen_loss is custom loss for generator\n",
        "    return total_gen_loss, gan_loss, l1_loss"
      ],
      "metadata": {
        "id": "Yk4-yfwU5AvZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator():\n",
        "    init = tf.random_normal_initializer(0., 0.02)\n",
        "\n",
        "    inp = Input(shape = [IMAGE_SIZE, IMAGE_SIZE, 3], name = \"input_image\")\n",
        "    tar = Input(shape = [IMAGE_SIZE, IMAGE_SIZE, 3], name = \"target_image\")\n",
        "    x = Concatenate()([inp, tar])\n",
        "    down1 = downsample(64,4,False)(x)\n",
        "    down2 = downsample(128, 4)(down1)\n",
        "    down3 = downsample(256, 4)(down2)\n",
        "\n",
        "    zero_pad1 = ZeroPadding2D()(down3)\n",
        "    conv = Conv2D(256, 4, strides = 1, kernel_initializer = init, use_bias = False)(zero_pad1)\n",
        "    leaky_relu = LeakyReLU()(conv)\n",
        "    zero_pad2 = ZeroPadding2D()(leaky_relu)\n",
        "    last = Conv2D(1, 4, strides = 1, kernel_initializer=init)(zero_pad2)\n",
        "    return Model(inputs = [inp, tar], outputs = last)"
      ],
      "metadata": {
        "id": "Ckn_5syeEFBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disc = discriminator()\n",
        "disc.summary()"
      ],
      "metadata": {
        "id": "3_rKQAObO2m4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(disc, show_shapes=True, dpi = 64)\n"
      ],
      "metadata": {
        "id": "D2FVf5utO2qK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def discriminator_loss(disc_real_output, disc_generated_output):\n",
        "    real_loss = loss_function(tf.ones_like(disc_real_output), disc_real_output)\n",
        "    generated_loss = loss_function(tf.zeros_like(disc_generated_output), disc_generated_output)\n",
        "    total_disc_loss = real_loss + generated_loss\n",
        "    return total_disc_loss"
      ],
      "metadata": {
        "id": "16t_NdzQO2tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_optimizer = Adam(lr= 2e-4, beta_1=0.5)\n",
        "discriminator_optimizer = Adam(lr = 2e-4, beta_1=0.5)"
      ],
      "metadata": {
        "id": "fRcx001MO2wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# after each epoch take one validation img and let generator predict it to see acc of generator\n",
        "\n",
        "def save_images(model, test_input, target, epoch):\n",
        "    prediction = model(test_input, training= True)\n",
        "    plt.figure(figsize = (15,15))\n",
        "    display_list= [test_input[0], target[0], prediction[0]]\n",
        "    title = [\"Input Image\", \"Ground Truth\", \"Predicton Image\"]\n",
        "    for i in range(3):\n",
        "        plt.subplot(1, 3, i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(display_list[i] * 0.5 + 0.5)\n",
        "        plt.axis(\"off\")\n",
        "    plt.savefig(f\"output/epoch_{epoch}.jpg\")\n",
        "    plt.close()\n"
      ],
      "metadata": {
        "id": "dIz6A3UGPKQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make sure output directory exists to save images\n",
        "if not os.path.exists(\"output\"):\n",
        "    os.mkdir(\"output\")"
      ],
      "metadata": {
        "id": "p0_zTYNYPKUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 50\n",
        "@tf.function\n",
        "def train_step(input_image, target, epoch):\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        gen_output = gen(input_image, training = True)\n",
        "\n",
        "        disc_real_output = disc([input_image, target], training = True)\n",
        "        disc_generated_output = disc([input_image, gen_output], training = True)\n",
        "        gen_total_loss, gen_gan_loss, gen_l1_loss = generator_loss(disc_generated_output, gen_output, target)\n",
        "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
        "        generator_gradients = gen_tape.gradient(gen_total_loss, gen.trainable_variables)\n",
        "        discriminator_gradients = disc_tape.gradient(disc_loss, disc.trainable_variables)\n",
        "        generator_optimizer.apply_gradients(zip(generator_gradients, gen.trainable_variables))\n",
        "        discriminator_optimizer.apply_gradients(zip(discriminator_gradients, disc.trainable_variables))\n",
        "        return gen_total_loss, disc_loss"
      ],
      "metadata": {
        "id": "iLo0LRk9PKXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(train_ds, epochs, test_ds):\n",
        "    for epoch in range(epochs):\n",
        "        start = time.time()\n",
        "        for input_, target in test_ds.take(1):\n",
        "            save_images(gen, input_, target, epoch)\n",
        "        # Train\n",
        "        print(f\"Epoch {epoch}\")\n",
        "        for n, (input_, target) in train_ds.enumerate():\n",
        "            gen_loss, disc_loss = train_step(input_, target, epoch)\n",
        "        print(\"Generator loss {:.2f} Discriminator loss {:.2f}\".format(gen_loss, disc_loss))\n",
        "        print(\"Time take for epoch {} is {} sec\\n\".format(epoch+1, time.time() - start))"
      ],
      "metadata": {
        "id": "RQJN0aMwPU5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "keras.backend.clear_session()"
      ],
      "metadata": {
        "id": "-LnEO_HYPUyv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fit(train_dataset, epochs, test_dataset)\n"
      ],
      "metadata": {
        "id": "xztZr7-_PKc9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JhO4epKpPKgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G7eUJhLkPKkJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}